<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.devzhang.cn","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="本章译自Apple官方文档AVFoundation Programming Guide, 是AVFoundation系列译文第五篇, 介绍了AVFoundation框架中利用硬件设备进行音视频或静态图像采集的相关内容, 全部译文参见我的GitBook: AVFoundation编程指南.">
<meta property="og:type" content="article">
<meta property="og:title" content="静态图片和视频捕捉">
<meta property="og:url" content="http://www.devzhang.cn/2016/09/18/%E9%9D%99%E6%80%81%E5%9B%BE%E7%89%87%E5%92%8C%E8%A7%86%E9%A2%91%E6%8D%95%E6%8D%89/index.html">
<meta property="og:site_name" content="做点有意思的事情">
<meta property="og:description" content="本章译自Apple官方文档AVFoundation Programming Guide, 是AVFoundation系列译文第五篇, 介绍了AVFoundation框架中利用硬件设备进行音视频或静态图像采集的相关内容, 全部译文参见我的GitBook: AVFoundation编程指南.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://developer.apple.com/library/prerelease/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/captureOverview_2x.png">
<meta property="og:image" content="https://developer.apple.com/library/prerelease/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/captureDetail_2x.png">
<meta property="og:image" content="https://developer.apple.com/library/prerelease/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/cameras_2x.png">
<meta property="article:published_time" content="2016-09-18T13:17:54.000Z">
<meta property="article:modified_time" content="2016-09-21T02:54:17.000Z">
<meta property="article:author" content="mangox">
<meta property="article:tag" content="AVFoundation编程指南">
<meta property="article:tag" content="翻译">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://developer.apple.com/library/prerelease/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/captureOverview_2x.png">

<link rel="canonical" href="http://www.devzhang.cn/2016/09/18/%E9%9D%99%E6%80%81%E5%9B%BE%E7%89%87%E5%92%8C%E8%A7%86%E9%A2%91%E6%8D%95%E6%8D%89/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>静态图片和视频捕捉 | 做点有意思的事情</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">做点有意思的事情</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">每天进步一点点</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.devzhang.cn/2016/09/18/%E9%9D%99%E6%80%81%E5%9B%BE%E7%89%87%E5%92%8C%E8%A7%86%E9%A2%91%E6%8D%95%E6%8D%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="mangox">
      <meta itemprop="description" content="每天进步一点点">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="做点有意思的事情">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          静态图片和视频捕捉
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-09-18 21:17:54" itemprop="dateCreated datePublished" datetime="2016-09-18T21:17:54+08:00">2016-09-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2016-09-21 10:54:17" itemprop="dateModified" datetime="2016-09-21T10:54:17+08:00">2016-09-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/iOS/" itemprop="url" rel="index"><span itemprop="name">iOS</span></a>
                </span>
            </span>

          
            <span id="/2016/09/18/%E9%9D%99%E6%80%81%E5%9B%BE%E7%89%87%E5%92%8C%E8%A7%86%E9%A2%91%E6%8D%95%E6%8D%89/" class="post-meta-item leancloud_visitors" data-flag-title="静态图片和视频捕捉" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2016/09/18/%E9%9D%99%E6%80%81%E5%9B%BE%E7%89%87%E5%92%8C%E8%A7%86%E9%A2%91%E6%8D%95%E6%8D%89/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2016/09/18/%E9%9D%99%E6%80%81%E5%9B%BE%E7%89%87%E5%92%8C%E8%A7%86%E9%A2%91%E6%8D%95%E6%8D%89/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本章译自Apple官方文档<a target="_blank" rel="noopener" href="https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/00_Introduction.html#//apple_ref/doc/uid/TP40010188-CH1-SW3">AVFoundation Programming Guide</a>, 是AVFoundation系列译文第五篇, 介绍了AVFoundation框架中利用硬件设备进行音视频或静态图像采集的相关内容, 全部译文参见我的GitBook: <a target="_blank" rel="noopener" href="https://www.gitbook.com/book/changjianfeishui/avfoundation-programming-guide/details">AVFoundation编程指南</a>. </p>
<span id="more"></span>

<p>通过输入(inputs)和输出(outputs)对象来对采集设备(比如摄像头或麦克风)进行管理. 使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession">AVCaptureSession</a>对象协调inputs和outputs之间的数据. </p>
<ul>
<li><a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice">AVCaptureDevice</a>代表输入设备, 比如摄像头和麦克风</li>
<li><a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureinput">AVCaptureInput</a>的子类用来对输入设备进行配置</li>
<li><a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureoutput">AVCaptureOutput</a>的子类用来设置输出结果为图片或者视频</li>
<li><a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession">AVCaptureSession</a>用来协调inputs和outputs之间的数据</li>
</ul>
<p>使用CALayer的子类<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideopreviewlayer">AVCaptureVideoPreviewLayer</a>, 可以展示摄像头采集的画面预览.</p>
<p>对于一个session, 可以配置多个inputs和outputs, 如图所示:</p>
<p><img src="https://developer.apple.com/library/prerelease/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/captureOverview_2x.png" alt="A single session can configure multiple inputs and outputs"></p>
<p>对于大部分的应用而言, 这已经足够了. 但是有些情况下, 会涉及到如何表示一个inputs的多个端口(ports), 以及这些ports如何连接到outputs.</p>
<p>Capture session中使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureconnection">AVCaptureConnection</a>表示inputs和outputs之间的连接. 一个Inputs包含一个或多个input ports(<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureinputport">AVCaptureInputPort</a>). Outputs可以从一个或多个来源接收数据, 比如<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturemoviefileoutput">AVCaptureMovieFileOutput</a>可以同时接收视频和音频数据.</p>
<p>如下图所示, 当在session中添加一个input或output时, session会为所有可匹配的inputs和outputs之前生成connections(<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureconnection">AVCaptureConnection</a>).</p>
<p><img src="https://developer.apple.com/library/prerelease/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/captureDetail_2x.png" alt="AVCaptureConnection represents a connection between an input and output"></p>
<p>可以使用一个connection来开启或关闭一个input或output数据流. 也可以使用connection监控一个audio频道的码率平均值和峰值.</p>
<blockquote>
<p>注意: 媒体捕捉不支持模拟器,也不能同时使用iOS设备上的前置摄像头和后置摄像头进行捕捉</p>
</blockquote>
<h1 id="使用Capture-Session协调数据流"><a href="#使用Capture-Session协调数据流" class="headerlink" title="使用Capture Session协调数据流"></a>使用Capture Session协调数据流</h1><p>数据采集管理的核心是<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession">AVCaptureSession</a>. 在session中添加采集设备并对output进行配置之后, 可以向session发送<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1388185-startrunning">startRunning</a>消息开始采集, 发送<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1385661-stoprunning">stopRunning</a>消息停止采集.</p>
<pre><code>AVCaptureSession *session = [[AVCaptureSession alloc] init];
// Add inputs and outputs.
[session startRunning];
</code></pre>
<h2 id="配置Capture-Session"><a href="#配置Capture-Session" class="headerlink" title="配置Capture Session"></a>配置Capture Session</h2><p>使用session的<code>sessionPreset</code>属性指定图片质量和分辨率:</p>
<ul>
<li>AVCaptureSessionPresetHigh: 高分辨率, 最终效果根据设备不同有所差异</li>
<li>AVCaptureSessionPresetMedium: 中等分辨率, 适合Wi-Fi分享. 最终效果根据设备不同有所差异</li>
<li>AVCaptureSessionPresetLow: 低分辨率, 适合3G分享, 最终效果根据设备不同有所差异</li>
<li>AVCaptureSessionPreset640x480: 640x480, VGA</li>
<li>AVCaptureSessionPreset1280x720: 1280x720, 720p HD</li>
<li>AVCaptureSessionPresetPhoto: 全屏照片, 不能用来作为输出视频</li>
</ul>
<p>在设置一个preset之前, 需要判断设备是否支持该preset值:</p>
<pre><code>if ([session canSetSessionPreset:AVCaptureSessionPreset1280x720]) &#123;
    session.sessionPreset = AVCaptureSessionPreset1280x720;
&#125;
else &#123;
    // Handle the failure.
&#125;
</code></pre>
<p>如果需要设置一个更高分辨率的preset, 或者在session运行时修改一些配置, 需要在<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1389174-beginconfiguration">beginConfiguration</a>和<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1388173-commitconfiguration">commitConfiguration</a>之间完成修改. <a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1389174-beginconfiguration">beginConfiguration</a>和<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1388173-commitconfiguration">commitConfiguration</a>方法确保所有的修改被整体应用, 减少对预览状态的影响. 在调用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1389174-beginconfiguration">beginConfiguration</a>之后, 可以添加或移除一个output, 修改<code>sessionPreset</code>属性, 或者单独配置input和output的属性. 只有调用了<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1388173-commitconfiguration">commitConfiguration</a>方法, 改变才会生效.</p>
<pre><code>[session beginConfiguration];
// Remove an existing capture device.
// Add a new capture device.
// Reset the preset.
[session commitConfiguration];
</code></pre>
<h2 id="监测Capture-Session的状态"><a href="#监测Capture-Session的状态" class="headerlink" title="监测Capture Session的状态"></a>监测Capture Session的状态</h2><p>可以使用通知(NSNotification)监测session的状态, 并且所有的通知都在主线程中发送. 注册监听<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/foundation/nsnotification.name/1389738-avcapturesessionruntimeerror">AVCaptureSessionRuntimeError</a>通知可以捕捉运行时发生的错误. 也可以使用session的<code>running</code>属性判断当前的运行状态, <code> interrupted</code>属性则可以判断当前是否中断. 此外, <code>running</code>和<code>interrupted</code>属性都可以通过KVO进行监听.</p>
<h1 id="使用AVCaptureDevice表示输入设备"><a href="#使用AVCaptureDevice表示输入设备" class="headerlink" title="使用AVCaptureDevice表示输入设备"></a>使用AVCaptureDevice表示输入设备</h1><p><a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice">AVCaptureDevice</a>是对实际的物理捕捉设备的抽象, 物体捕捉设备向<code>AVCaptureSession</code>提供数据. 每个<code>AVCaptureDevice</code>对象代表一个实际的输入设备, 例如前摄像头或后摄像头, 或麦克风.</p>
<p>使用<code>AVCaptureDevice</code>类的<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1386237-devices">devices</a>和<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1390520-deviceswithmediatype">devicesWithMediaType:</a>方法可以获取当前可用的捕捉设备. 而且可以获取捕捉设备的设备特性(参见<a target="_blank" rel="noopener" href="https://developer.apple.com/library/prerelease/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/04_MediaCapture.html#//apple_ref/doc/uid/TP40010188-CH5-SW18">Device Capture Settings</a>). 当前的可用设备的状态可能会发生改变, 当前使用的输入设备可能会变为不可用状态(如果设备被另外一个应用使用), 也可能会有新的设备变为可用状态(被其他应用释放). 注册接收<code>AVCaptureDeviceWasConnectedNotification</code>和<code>AVCaptureDeviceWasDisconnectedNotification</code>通知可以得知可用设备列表的变化.</p>
<h2 id="设备特性"><a href="#设备特性" class="headerlink" title="设备特性"></a>设备特性</h2><p>可以获取一个设备的设备特性. 也可以通过<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1389487-hasmediatype">hasMediaType:</a>方法判断设备是否支持特定媒体类型的捕捉, 通过<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1386263-supportsavcapturesessionpreset">supportsAVCaptureSessionPreset:</a>判断设备是否支持特定的分辨率. 当要提供一个可用的捕捉设备列表给用户进行选择时, 获取展示出设备的位置以及名称(比如前摄像头或后摄像头)拥有更好的用户体验.</p>
<p>下图展示了前摄像头(<code>AVCaptureDevicePositionFront</code>)和后摄像头(<code>AVCaptureDevicePositionBack</code>):</p>
<p><img src="https://developer.apple.com/library/prerelease/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/cameras_2x.png" alt="iOS device front and back facing camera positions"></p>
<p>下面的代码遍历了所有的可用设备并打印其名称, 如果是视频设备, 则打印其位置:</p>
<pre><code>NSArray *devices = [AVCaptureDevice devices];
 
for (AVCaptureDevice *device in devices) &#123;
 
    NSLog(@&quot;Device name: %@&quot;, [device localizedName]);
 
    if ([device hasMediaType:AVMediaTypeVideo]) &#123;
 
        if ([device position] == AVCaptureDevicePositionBack) &#123;
            NSLog(@&quot;Device position : back&quot;);
        &#125;
        else &#123;
            NSLog(@&quot;Device position : front&quot;);
        &#125;
    &#125;
&#125;
</code></pre>
<p>此外, 还可以获取设备的model ID以及unique ID.</p>
<h2 id="捕捉设置"><a href="#捕捉设置" class="headerlink" title="捕捉设置"></a>捕捉设置</h2><p>不同的设备之间存在性能差异, 比如一些设备支持特殊的对焦或闪光灯模式, 某些设备还支持兴趣点对焦.</p>
<p>下面的代码示例了如何找出一个支持手电筒模式和特定preset的设备:</p>
<pre><code>NSArray *devices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];
NSMutableArray *torchDevices = [[NSMutableArray alloc] init];
 
for (AVCaptureDevice *device in devices) &#123;
    [if ([device hasTorch] &amp;&amp;
         [device supportsAVCaptureSessionPreset:AVCaptureSessionPreset640x480]) &#123;
        [torchDevices addObject:device];
    &#125;
&#125;
</code></pre>
<p>如果找到了多个符合要求的设备, 你可能需要让用户选择其中的某一个设备, 这时可以使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1388222-localizedname">localizedName</a>属性获取设备的描述信息.</p>
<p>可以用类似的方式实现各种不同的捕捉设置. 框架预定义了一些常量用来代表特定的捕捉模式, 你可以使用这些常量以便于判断设备是否支持特定的模式. 在大部分情况下, 可以通过属性监听获取设备特性的变化状态. 任何情况下, 在改变设备的捕捉设置之前, 都应该先锁定设备, 详见下节<code>设备的配置</code>.</p>
<blockquote>
<p>兴趣点对焦模式和兴趣点曝光模式是互斥的, 正如对焦模式和曝光模式也是互斥的一样</p>
</blockquote>
<h3 id="对焦模式"><a href="#对焦模式" class="headerlink" title="对焦模式"></a>对焦模式</h3><p>有三种对焦模式:</p>
<ul>
<li><code>AVCaptureFocusModeLocked</code>: 固定焦点</li>
<li><code>AVCaptureFocusModeAutoFocus</code>: 自动对焦然后锁定焦点</li>
<li><code>AVCaptureFocusModeContinuousAutoFocus</code>: 连续自动对焦</li>
</ul>
<p>使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1390215-isfocusmodesupported">isFocusModeSupported:</a>方法判断设备是否支持给定的对焦模式, 然后设置属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1389191-focusmode">focusMode</a>改变对焦模式.</p>
<p>此外, 一些设备还支持兴趣点对焦模式. 通过方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1390436-isfocuspointofinterestsupported">focusPointOfInterestSupported</a>判断是否支持该模式, 然后使用属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1385853-focuspointofinterest">focusPointOfInterest</a>设置焦点. 无论设备是横屏(Home键靠右)或竖屏模式, CGPoint{0,0}代表设备左上角, CGPoint{1,1}代表设备右下角. </p>
<p>属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1390577-adjustingfocus">adjustingFocus</a>可以用来判断当前设备是否正在对焦中. 可以使用KVO监听该属性获取对焦开始与结束的通知.</p>
<p>设置对焦模式的示例代码如下:</p>
<pre><code>if ([currentDevice isFocusModeSupported:AVCaptureFocusModeContinuousAutoFocus]) &#123;
    CGPoint autofocusPoint = CGPointMake(0.5f, 0.5f);
    [currentDevice setFocusPointOfInterest:autofocusPoint];
    [currentDevice setFocusMode:AVCaptureFocusModeContinuousAutoFocus];
&#125;
</code></pre>
<h3 id="曝光模式"><a href="#曝光模式" class="headerlink" title="曝光模式"></a>曝光模式</h3><p>有两种曝光模式:</p>
<ul>
<li><code>AVCaptureExposureModeContinuousAutoExposure</code>: 自动调整曝光等级</li>
<li><code>AVCaptureExposureModeLocked</code>: 固定曝光等级</li>
</ul>
<p>使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1389048-isexposuremodesupported">isExposureModeSupported:</a>方法判断设备是否支持给定的曝光模式, 然后设置属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1388858-exposuremode">exposureMode</a>改变曝光模式.	<br>此外, 一些设备还支持兴趣点曝光模式. 通过方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1387263-exposurepointofinterestsupported">exposurePointOfInterestSupported</a>判断是否支持该模式, 然后使用属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1388777-exposurepointofinterest">exposurePointOfInterest</a>设置曝光点. 无论设备是横屏(Home键靠右)或竖屏模式, CGPoint{0,0}代表设备左上角, CGPoint{1,1}代表设备右下角. </p>
<p>属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1386253-adjustingexposure">adjustingExposure</a>可以用来判断当前设备是否正在改变曝光设置中. 可以使用KVO监听该属性获取开始设置曝光模式与结束设置曝光模式的通知. </p>
<p>设置曝光模式的示例代码如下:</p>
<pre><code>if ([currentDevice isExposureModeSupported:AVCaptureExposureModeContinuousAutoExposure]) &#123;
    CGPoint exposurePoint = CGPointMake(0.5f, 0.5f);
    [currentDevice setExposurePointOfInterest:exposurePoint];
    [currentDevice setExposureMode:AVCaptureExposureModeContinuousAutoExposure];
&#125;
</code></pre>
<h3 id="闪光模式"><a href="#闪光模式" class="headerlink" title="闪光模式"></a>闪光模式</h3><p>有三种闪光模式:</p>
<ul>
<li><code>AVCaptureFlashModeOff</code>: 关闭</li>
<li><code>AVCaptureFlashModeOn</code>: 打开</li>
<li><code>AVCaptureFlashModeAuto</code>: 根据环境亮度自动开启或关闭</li>
</ul>
<p>使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1388988-hasflash">hasFlash</a>判断一个设备是否有闪光灯. 使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1386434-isflashmodesupported">isFlashModeSupported:</a>判断是否支持某个闪光模式, 使用属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1388116-flashmode">flashMode</a>设置闪光灯模式.</p>
<h3 id="手电筒模式"><a href="#手电筒模式" class="headerlink" title="手电筒模式"></a>手电筒模式</h3><p>手电筒模式下, 闪光灯会一直处于开启状态, 用于视频捕捉. 有三种手电筒模式:</p>
<ul>
<li><code>AVCaptureTorchModeOff</code>: 关闭</li>
<li><code>AVCaptureTorchModeOn</code>: 打开</li>
<li><code>AVCaptureTorchModeAuto</code>: 根据需要自动开启或关闭</li>
</ul>
<p>使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1387674-hastorch">hasTorch</a>判断一个设备是否有闪光灯. 使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1388822-istorchmodesupported">isTorchModeSupported:</a>判断是否支持某个手电筒模式, 使用属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1386035-torchmode">torchMode</a>设置手电筒模式.</p>
<p>对于一个有手电筒的设备, 手电筒只有在设备与一个运行中的 capture session进行了关联后才可以设置为开启.</p>
<h3 id="视频稳定性"><a href="#视频稳定性" class="headerlink" title="视频稳定性"></a>视频稳定性</h3><p>依赖于某些特殊的硬件设备, 视频会有更好设置达到电影级别的稳定性. 但并不支持所有的视频格式和分辨率. </p>
<p>开启电影级别的视频稳定性特性在捕捉视频时可能会增加延迟. 使用属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureconnection/1620485-isvideostabilizationenabled">videoStabilizationEnabled</a>可以判断当前是否使用了视频稳定性特性. 属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureconnection/1620482-enablesvideostabilizationwhenava">enablesVideoStabilizationWhenAvailable</a>可以在设备支持的情况下自动开启视频稳定性特性, 该属性默认为关闭状态.</p>
<h3 id="白平衡"><a href="#白平衡" class="headerlink" title="白平衡"></a>白平衡</h3><p>有两种白平衡模式:</p>
<ul>
<li><code>AVCaptureWhiteBalanceModeLocked</code>: 固定参数的白平衡</li>
<li><code>AVCaptureWhiteBalanceModeContinuousAutoWhiteBalance</code>: 由相机自动调整白平衡参数</li>
</ul>
<p>使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1388587-iswhitebalancemodesupported">isWhiteBalanceModeSupported:</a>判断设备是否支持给定的白平衡模式, 然后通过属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1386369-whitebalancemode">whiteBalanceMode</a>设置白平衡模式.</p>
<p>使用属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1386544-adjustingwhitebalance">adjustingWhiteBalance</a>判断当前是否正在修改白平衡模式. 可以使用KVO监听该属性获取开始设置白平衡模式与结束设置白平衡模式的通知. </p>
<h3 id="设置设备方向"><a href="#设置设备方向" class="headerlink" title="设置设备方向"></a>设置设备方向</h3><p>可以在<code>AVCaptureConnection</code>上指定期望的设备方向, 用来设置输出时<code>AVCaptureOutput</code>(<code>AVCaptureMovieFileOutput</code>, <code>AVCaptureStillImageOutput</code>和<code>AVCaptureVideoDataOutput</code>)的设备方向.</p>
<p>使用属性<code>AVCaptureConnectionsupportsVideoOrientation</code>判断设备是否支持修改视频方向, 使用属性<code>videoOrientation</code>指定一个方向. 下面的代码将<code>AVCaptureConnection</code>的方向设置为<code>AVCaptureVideoOrientationLandscapeLeft</code>:</p>
<pre><code>AVCaptureConnection *captureConnection = &lt;#A capture connection#&gt;;
if ([captureConnection isVideoOrientationSupported])
&#123;
    AVCaptureVideoOrientation orientation = AVCaptureVideoOrientationLandscapeLeft;
    [captureConnection setVideoOrientation:orientation];
&#125;
</code></pre>
<h2 id="设备配置"><a href="#设备配置" class="headerlink" title="设备配置"></a>设备配置</h2><p>要修改设备的捕捉属性, 首先需要使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturedevice/1387810-lockforconfiguration">lockForConfiguration:</a>锁定设备, 这样可以避免与其他应用的设置产生冲突. </p>
<pre><code>if ([device isFocusModeSupported:AVCaptureFocusModeLocked]) &#123;
    NSError *error = nil;
    if ([device lockForConfiguration:&amp;error]) &#123;
        device.focusMode = AVCaptureFocusModeLocked;
        [device unlockForConfiguration];
    &#125;
    else &#123;
        // Respond to the failure as appropriate.
        
    &#125;
    
</code></pre>
<h2 id="切换设备"><a href="#切换设备" class="headerlink" title="切换设备"></a>切换设备</h2><p>某些场景下可能需要允许用户切换输入设备, 比如前后摄像头. 为了避免卡顿, 可以重新配置正在运行的session, 但是嵌套使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1389174-beginconfiguration">beginConfiguration</a>和<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturesession/1388173-commitconfiguration">commitConfiguration</a>方法.</p>
<pre><code>AVCaptureSession *session = &lt;#A capture session#&gt;;
[session beginConfiguration];
 
[session removeInput:frontFacingCameraDeviceInput];
[session addInput:backFacingCameraDeviceInput];
 
[session commitConfiguration];
</code></pre>
<p>当最后的<code>commitConfiguration</code>方法被调用时, 所有的设置变化会一起执行, 确保了切换的流畅性.	        </p>
<h1 id="使用AVCaptureInput添加输入设备"><a href="#使用AVCaptureInput添加输入设备" class="headerlink" title="使用AVCaptureInput添加输入设备"></a>使用AVCaptureInput添加输入设备</h1><p>要把一个capture device添加到capture session中, 需要使用<a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureDeviceInput_Class/index.html#//apple_ref/occ/cl/AVCaptureDeviceInput">AVCaptureDeviceInput</a>(抽象类<code>AVCaptureInput</code>的子类). Capture device input 管理设备的端口.</p>
<pre><code>NSError *error;
AVCaptureDeviceInput *input =
        [AVCaptureDeviceInput deviceInputWithDevice:device error:&amp;error];
if (!input) &#123;
    // Handle the error appropriately.
&#125;
</code></pre>
<p>使用<a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureSession_Class/index.html#//apple_ref/occ/instm/AVCaptureSession/addInput:">addInput:</a>添加输入. 使用<a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureSession_Class/index.html#//apple_ref/occ/instm/AVCaptureSession/canAddInput:">canAddInput:</a>判断该设备是否可以被添加到session中.</p>
<pre><code>AVCaptureSession *captureSession = &lt;#Get a capture session#&gt;;
AVCaptureDeviceInput *captureDeviceInput = &lt;#Get a capture device input#&gt;;
if ([captureSession canAddInput:captureDeviceInput]) &#123;
    [captureSession addInput:captureDeviceInput];
&#125;
else &#123;
    // Handle the failure.
&#125;	
</code></pre>
<p>一个<code>AVCaptureInput</code>对象包含一个或多个数据流. 例如, 输入设备可能同时提供音频和视频数据. 每个<a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureInputPort_Class/index.html#//apple_ref/occ/cl/AVCaptureInputPort">AVCaptureInputPort</a>对象代表一个媒体数据流. Capture session使用一个<code>AVCaptureConnection</code>对象定义一组<code>AVCaptureInputPort</code>和一个<code>AVCaptureOutput</code>之间的映射关系.</p>
<h1 id="使用AVCaptureOutput输出数据"><a href="#使用AVCaptureOutput输出数据" class="headerlink" title="使用AVCaptureOutput输出数据"></a>使用AVCaptureOutput输出数据</h1><p>要从capture session中输出数据, 可以向其添加一个或多个outputs(<a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureOutput_Class/index.html#//apple_ref/occ/cl/AVCaptureOutput">AVCaptureOutput</a>的子类), 你可以使用:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureMovieFileOutput_Class/index.html#//apple_ref/occ/cl/AVCaptureMovieFileOutput">AVCaptureMovieFileOutput</a>: 输出为电影文件</li>
<li><a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureVideoDataOutput_Class/index.html#//apple_ref/occ/cl/AVCaptureVideoDataOutput">AVCaptureVideoDataOutput</a>: 可以逐帧处理捕捉到的视频</li>
<li><a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureAudioDataOutput_Class/index.html#//apple_ref/occ/cl/AVCaptureAudioDataOutput">AVCaptureAudioDataOutput</a>: 可以处理捕捉到的音频数据</li>
<li><a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureStillImageOutput_Class/index.html#//apple_ref/occ/cl/AVCaptureStillImageOutput">AVCaptureStillImageOutput</a>: 输出为静态图片</li>
</ul>
<p>使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureSession_Class/index.html#//apple_ref/occ/instm/AVCaptureSession/addOutput:">addOutput:</a>在capture session中添加outputs. 使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureSession_Class/index.html#//apple_ref/occ/instm/AVCaptureSession/canAddOutput:">canAddOutput:</a>判断是否可以添加一个给定的output. 可以根据需要在session运行过程中添加或移除一个output.</p>
<pre><code>AVCaptureSession *captureSession = &lt;#Get a capture session#&gt;;
AVCaptureMovieFileOutput *movieOutput = &lt;#Create and configure a movie output#&gt;;
if ([captureSession canAddOutput:movieOutput]) &#123;
    [captureSession addOutput:movieOutput];
&#125;
else &#123;
    // Handle the failure.
&#125;
</code></pre>
<h2 id="输出为视频文件"><a href="#输出为视频文件" class="headerlink" title="输出为视频文件"></a>输出为视频文件</h2><p>使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturemoviefileoutput">AVCaptureMovieFileOutput</a>将视频数据保存为一个本地文件. 可以对movie file output的参数进行配置, 比如最大的录制时长, 最大的录制文件大小, 如果设备磁盘空间不足的话, 还可以阻止用户进行视频录制.</p>
<pre><code>AVCaptureMovieFileOutput *aMovieFileOutput = [[AVCaptureMovieFileOutput alloc] init];
CMTime maxDuration = &lt;#Create a CMTime to represent the maximum duration#&gt;;
aMovieFileOutput.maxRecordedDuration = maxDuration;
aMovieFileOutput.minFreeDiskSpaceLimit = &lt;#An appropriate minimum given the quality of the movie format and the duration#&gt;;
</code></pre>
<p>输出的分辨率和码率依赖于capture session的<code> sessionPreset</code> 属性, 常用的视频编码格式是H.264, 音频编码格式是AAC. 实际的编码格式可能由于设备不同有所差异.</p>
<h3 id="开始录制"><a href="#开始录制" class="headerlink" title="开始录制"></a>开始录制</h3><p>使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturefileoutput/1387224-startrecordingtooutputfileurl">startRecordingToOutputFileURL:recordingDelegate:</a>开始录制一段QuickTime视频, 方法中需要传入一个本地文件的URL和一个录制的delegate. 传入的本地URL不能是已经存在的文件, 因为movie file output不会对已存在的文件进行重写, 而且对传入的文件路径, 程序必须有写入权限. 传入的delegate必须遵循<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturefileoutputrecordingdelegate">AVCaptureFileOutputRecordingDelegate</a>协议, 且必须实现<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturefileoutputrecordingdelegate/1390612-captureoutput">captureOutput:didFinishRecordingToOutputFileAtURL:fromConnections:error:</a>方法. 在这个代理方法中, delegate可能会向相册写入数据, 需要对错误进行检测.</p>
<pre><code>AVCaptureMovieFileOutput *aMovieFileOutput = &lt;#Get a movie file output#&gt;;
NSURL *fileURL = &lt;#A file URL that identifies the output location#&gt;;
[aMovieFileOutput startRecordingToOutputFileURL:fileURL recordingDelegate:&lt;#The delegate#&gt;]; 	
</code></pre>
<h3 id="确保文件写入成功"><a href="#确保文件写入成功" class="headerlink" title="确保文件写入成功"></a>确保文件写入成功</h3><p>要判断文件是否写入成功, 在<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturefileoutputrecordingdelegate/1390612-captureoutput">captureOutput:didFinishRecordingToOutputFileAtURL:fromConnections:error:</a>方法中不仅需要检测error, 还需要对error中的user info字典中的<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/averrorrecordingsuccessfullyfinishedkey">AVErrorRecordingSuccessfullyFinishedKey</a>进行判断.</p>
<pre><code>- (void)captureOutput:(AVCaptureFileOutput *)captureOutput
        didFinishRecordingToOutputFileAtURL:(NSURL *)outputFileURL
        fromConnections:(NSArray *)connections
        error:(NSError *)error &#123;
 
    BOOL recordedSuccessfully = YES;
    if ([error code] != noErr) &#123;
        // A problem occurred: Find out if the recording was successful.
        id value = [[error userInfo] objectForKey:AVErrorRecordingSuccessfullyFinishedKey];
        if (value) &#123;
            recordedSuccessfully = [value boolValue];
        &#125;
    &#125;
    // Continue as appropriate...
</code></pre>
<p>需要对<code>AVErrorRecordingSuccessfullyFinishedKey</code>进行判断是因为即使写入过程中抛出了一个error, 文件也可能被成功写入了. 抛出的error可能是因为达到了一些设置的限制约束条件, 比如<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/averror.code/1390284-maximumdurationreached">AVErrorMaximumDurationReached</a>, 以及<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/averror/averrormaximumfilesizereached">AVErrorMaximumFileSizeReached</a>. 其他可能导致录制中断的情况如下:</p>
<ul>
<li>磁盘已满 - <a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/averror/averrordiskfull">AVErrorDiskFull</a></li>
<li>与录制的设备的连接断开 - <a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/averror/averrordevicewasdisconnected">AVErrorDeviceWasDisconnected</a></li>
<li>session中断(比如有电话接入) - <a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/averror/averrorsessionwasinterrupted">AVErrorSessionWasInterrupted</a></li>
</ul>
<h3 id="在文件中添加元数据"><a href="#在文件中添加元数据" class="headerlink" title="在文件中添加元数据"></a>在文件中添加元数据</h3><p>可在任何时刻对文件的元数据(metadata)进行设置, 哪怕是在录制过程中. 一个file output的metadata由一个<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avmetadataitem">AVMetadataItem</a>对象的数组来表示. 可以使用其可变子类<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avmutablemetadataitem">AVMutableMetadataItem</a>创建自定义的metadata.</p>
<pre><code>AVCaptureMovieFileOutput *aMovieFileOutput = &lt;#Get a movie file output#&gt;;
NSArray *existingMetadataArray = aMovieFileOutput.metadata;
NSMutableArray *newMetadataArray = nil;
if (existingMetadataArray) &#123;
    newMetadataArray = [existingMetadataArray mutableCopy];
&#125;
else &#123;
    newMetadataArray = [[NSMutableArray alloc] init];
&#125;
 
AVMutableMetadataItem *item = [[AVMutableMetadataItem alloc] init];
item.keySpace = AVMetadataKeySpaceCommon;
item.key = AVMetadataCommonKeyLocation;
 
CLLocation *location - &lt;#The location to set#&gt;;
item.value = [NSString stringWithFormat:@&quot;%+08.4lf%+09.4lf/&quot;
    location.coordinate.latitude, location.coordinate.longitude];
 
[newMetadataArray addObject:item];
 
aMovieFileOutput.metadata = newMetadataArray;
</code></pre>
<h2 id="处理视频帧"><a href="#处理视频帧" class="headerlink" title="处理视频帧"></a>处理视频帧</h2><p><a target="_blank" rel="noopener" href="https://developer.apple.com/library/ios/documentation/AVFoundation/Reference/AVCaptureVideoDataOutput_Class/index.html#//apple_ref/occ/cl/AVCaptureVideoDataOutput">AVCaptureVideoDataOutput</a>使用代理模式来对视频帧进行处理. 使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideodataoutput/1389008-setsamplebufferdelegate">setSampleBufferDelegate:queue:</a>设置代理, 此外还需要传入代理方法被调用的队列. 必须使用同步队列确保视频帧按照录制顺序被传递到代理方法中. 可以使用队列修改视频帧传递处理的优先级, 参见示例<a target="_blank" rel="noopener" href="https://developer.apple.com/library/content/samplecode/SquareCam/Introduction/Intro.html#//apple_ref/doc/uid/DTS40011190">SquareCam</a>.</p>
<p>在代理方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideodataoutputsamplebufferdelegate/1385775-captureoutput">captureOutput:didOutputSampleBuffer:fromConnection:</a>中, 视频帧由<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/coremedia/cmsamplebuffer">CMSampleBufferRef</a>类型表示. 默认情况下, buffers被设置为当前设备相机效率最高的格式. 也可以使用属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideodataoutput/1389945-videosettings">videoSettings</a>自定义输出格式. <code>videoSettings</code>属性是一个字典类型, 目前只支持<code>kCVPixelBufferPixelFormatTypeKey</code>. 系统建议的视频格式可以通过属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideodataoutput/1387050-availablevideocvpixelformattypes">availableVideoCVPixelFormatTypes</a>获取, 属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideodataoutput/1389227-availablevideocodectypes">availableVideoCodecTypes</a>返回支持的编码格式. Core Graphics和OpenGL都很好的兼容了<code>BGRA</code>格式.</p>
<pre><code>AVCaptureVideoDataOutput *videoDataOutput = [AVCaptureVideoDataOutput new];
NSDictionary *newSettings =
                @&#123; (NSString *)kCVPixelBufferPixelFormatTypeKey : @(kCVPixelFormatType_32BGRA) &#125;;
videoDataOutput.videoSettings = newSettings;
 
 // discard if the data output queue is blocked (as we process the still image
[videoDataOutput setAlwaysDiscardsLateVideoFrames:YES];)
 
// create a serial dispatch queue used for the sample buffer delegate as well as when a still image is captured
// a serial dispatch queue must be used to guarantee that video frames will be delivered in order
// see the header doc for setSampleBufferDelegate:queue: for more information
videoDataOutputQueue = dispatch_queue_create(&quot;VideoDataOutputQueue&quot;, DISPATCH_QUEUE_SERIAL);
[videoDataOutput setSampleBufferDelegate:self queue:videoDataOutputQueue];
 
AVCaptureSession *captureSession = &lt;#The Capture Session#&gt;;
 
if ( [captureSession canAddOutput:videoDataOutput] )
     [captureSession addOutput:videoDataOutput];
 
</code></pre>
<h3 id="视频处理时的性能考虑"><a href="#视频处理时的性能考虑" class="headerlink" title="视频处理时的性能考虑"></a>视频处理时的性能考虑</h3><p>导出视频应当尽可能的使用低分辨率, 高分辨率会消耗额外的CPU和电量.</p>
<p>确保在代理方法<code>captureOutput:didOutputSampleBuffer:fromConnection:</code>中处理sample buffer时不要使用耗时操作, 如果处理占用时间过长, AV Foundation会停止向代理方法中传递视频帧, 而且会停止其他的输出, 比如preview layer上的预览.</p>
<p>可以设置capture video data的属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideodataoutput/1616296-minframeduration">minFrameDuration</a>通过降低帧率来确保有足够的时间对视频帧进行处理. 将属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideodataoutput/1385780-alwaysdiscardslatevideoframes">alwaysDiscardsLateVideoFrames</a>设置为<code>YES</code>(默认值)的话, 后面的视频帧将会被丢弃, 而不是排队等待处理. 如果你并不介意延迟, 而且需要处理所有的视频帧, 也可以将<code>alwaysDiscardsLateVideoFrames</code>设置为<code>NO</code>(即使如此, 也可能会出现掉帧的情况).</p>
<h2 id="捕捉静态图像"><a href="#捕捉静态图像" class="headerlink" title="捕捉静态图像"></a>捕捉静态图像</h2><p>使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturestillimageoutput">AVCaptureStillImageOutput</a>捕捉带元数据的静态图像. 	图片的分辨率依赖于session的preset设置和具体的硬件设备.</p>
<h3 id="像素和编码格式"><a href="#像素和编码格式" class="headerlink" title="像素和编码格式"></a>像素和编码格式</h3><p>不同的设备支持不同的图片格式. 可以使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturestillimageoutput/1388622-availableimagedatacvpixelformatt">availableImageDataCVPixelFormatTypes</a>获取设备支持的所有像素格式, 使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturestillimageoutput/1388312-availableimagedatacodectypes">availableImageDataCodecTypes</a>可以获取设备支持的图像编码类型. 设置属性字典<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturestillimageoutput/1389306-outputsettings">outputSettings</a>可以指定需要的图片格式:()</p>
<pre><code>AVCaptureStillImageOutput *stillImageOutput = [[AVCaptureStillImageOutput alloc] init];
NSDictionary *outputSettings = @&#123; AVVideoCodecKey : AVVideoCodecJPEG&#125;;
[stillImageOutput setOutputSettings:outputSettings];
</code></pre>
<p>如果需要的是JPEG图片, 则不要指定压缩格式. 相反, 应该让still image output进行压缩(硬件加速). 可以使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturestillimageoutput/1388131-jpegstillimagensdatarepresentati">jpegStillImageNSDataRepresentation:</a>将图片转换为无压缩的<code>NSData</code>对象.</p>
<h3 id="捕捉图片"><a href="#捕捉图片" class="headerlink" title="捕捉图片"></a>捕捉图片</h3><p>使用方法<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturestillimageoutput/1387374-capturestillimageasynchronously">captureStillImageAsynchronouslyFromConnection:completionHandler:</a>捕捉图片. 第一个参数是需要捕捉的connection, 需要判断当前的connection中哪个input正在采集视频.</p>
<pre><code>AVCaptureConnection *videoConnection = nil;
for (AVCaptureConnection *connection in stillImageOutput.connections) &#123;
    for (AVCaptureInputPort *port in [connection inputPorts]) &#123;
        if ([[port mediaType] isEqual:AVMediaTypeVideo] ) &#123;
            videoConnection = connection;
            break;
        &#125;
    &#125;
    if (videoConnection) &#123; break; &#125;
&#125;
</code></pre>
<p>方法的第二个参数是一个有两个参数的<code>block</code>: 一个包含图像数据的<code>CMSampleBuffer</code>类型, 另一个是NSError对象. Sample buffer自身包含了元数据, 比如EXIF信息字典, 可以对这些元数据进行修改.</p>
<pre><code>[stillImageOutput captureStillImageAsynchronouslyFromConnection:videoConnection completionHandler:
    ^(CMSampleBufferRef imageSampleBuffer, NSError *error) &#123;
        CFDictionaryRef exifAttachments =
            CMGetAttachment(imageSampleBuffer, kCGImagePropertyExifDictionary, NULL);
        if (exifAttachments) &#123;
            // Do something with the attachments.
        &#125;
        // Continue as appropriate.
    &#125;];
    
</code></pre>
<h1 id="录制预览"><a href="#录制预览" class="headerlink" title="录制预览"></a>录制预览</h1><p>可以提供给用户一个preview, 用来展示正在通过摄像头录制的内容(使用preview layer), 或者正在通过麦克风记录的音频内容(通过监听audio channel).</p>
<h2 id="视频预览"><a href="#视频预览" class="headerlink" title="视频预览"></a>视频预览</h2><p>使用 <a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideopreviewlayer">AVCaptureVideoPreviewLayer</a>可以进行视频预览. <code>AVCaptureVideoPreviewLayer</code>是<code>CALayer</code>的子类. 进行视频预览不需要设置任何的output对象. 	    </p>
<p>使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideodataoutput">AVCaptureVideoDataOutput</a>类可以在视频展示给用户预览之前对视频进行处理.</p>
<p>与capture output不同, 一个video preview layer会强引用与其相关联的session. 这是为了确保在进行视频预览时session不会被销毁.</p>
<pre><code>AVCaptureSession *captureSession = &lt;#Get a capture session#&gt;;
CALayer *viewLayer = &lt;#Get a layer from the view in which you want to present the preview#&gt;;
 
AVCaptureVideoPreviewLayer *captureVideoPreviewLayer = [[AVCaptureVideoPreviewLayer alloc] initWithSession:captureSession];
[viewLayer addSublayer:captureVideoPreviewLayer];
</code></pre>
<p>大体上, video preview layer的性质与<code>CALayer</code>类似. 你可以对图像进行缩放, 向操作其他任何layer一样进行transformations, rotations等操作. 一个不同点在于你可能需要设置layer的<code>orientation</code>属性指定如何对摄像头捕捉的图像方向进行旋转. 此外, 通过属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureconnection/1387424-supportsvideomirroring">supportsVideoMirroring</a>可以判断设备是否支持预览镜像. 属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureconnection/1387082-automaticallyadjustsvideomirrori">automaticallyAdjustsVideoMirroring</a>的默认值为<code>YES</code>, 但是仍然可以根据需要设置属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureconnection/1389172-isvideomirrored">videoMirrored</a>进行修改. </p>
<h3 id="视频重力模式"><a href="#视频重力模式" class="headerlink" title="视频重力模式"></a>视频重力模式</h3><p>Preview layer支持三种重力模式, 可以使用属性<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcapturevideopreviewlayer/1386708-videogravity">videoGravity</a>进行设置: </p>
<ul>
<li><code>AVLayerVideoGravityResizeAspect</code>: 保持视频款高比, 当视频内容不能铺满屏幕时, 不足的部分使用黑色背景进行填充.</li>
<li><code>AVLayerVideoGravityResizeAspectFill</code>: 保持视频款高比, 但是会铺满整个屏幕, 必要时会对视频内容进行裁剪.</li>
<li><code>AVLayerVideoGravityResize</code>: 拉伸视频内容铺满屏幕, 可能导致图像变形.</li>
</ul>
<h3 id="预览时使用点击聚焦功能"><a href="#预览时使用点击聚焦功能" class="headerlink" title="预览时使用点击聚焦功能"></a>预览时使用点击聚焦功能</h3><p>在preview layer上实现点击聚焦功能时, 需要注意视频方向, 视频重力模式以及可能设置了视频镜像. 参见代码示例<a target="_blank" rel="noopener" href="https://developer.apple.com/library/content/samplecode/AVCam/Introduction/Intro.html#//apple_ref/doc/uid/DTS40010112">AVCam-iOS: Using AVFoundation to Capture Images and Movies</a>.</p>
<h2 id="展示声音等级"><a href="#展示声音等级" class="headerlink" title="展示声音等级"></a>展示声音等级</h2><p>要在capture connection中检测声音的均值和峰值, 可以使用<a target="_blank" rel="noopener" href="https://developer.apple.com/reference/avfoundation/avcaptureaudiochannel">AVCaptureAudioChannel</a>对象. 声音等级不能使用KVO的方式获取, 所以需要根据界面更新的需求定时进行轮询(比如每秒10次).</p>
<pre><code>AVCaptureAudioDataOutput *audioDataOutput = &lt;#Get the audio data output#&gt;;
NSArray *connections = audioDataOutput.connections;
if ([connections count] &gt; 0) &#123;
    // There should be only one connection to an AVCaptureAudioDataOutput.
    AVCaptureConnection *connection = [connections objectAtIndex:0];
 
    NSArray *audioChannels = connection.audioChannels;
 
    for (AVCaptureAudioChannel *channel in audioChannels) &#123;
        float avg = channel.averagePowerLevel;
        float peak = channel.peakHoldLevel;
        // Update the level meter user interface.
    &#125;
&#125;
</code></pre>
<h1 id="示例-捕捉视频帧为UIImage对象"><a href="#示例-捕捉视频帧为UIImage对象" class="headerlink" title="示例: 捕捉视频帧为UIImage对象"></a>示例: 捕捉视频帧为UIImage对象</h1><p>接下来的代码简单示例了如何捕捉视频, 并将捕捉到的视频帧转换为UIImage对象:</p>
<ul>
<li>创建<code>AVCaptureSession</code>对象</li>
<li>找到合适类型的<code>AVCaptureDevice</code>对象进行输入</li>
<li>为设备创建<code>AVCaptureDeviceInput</code>对象</li>
<li>创建<code>AVCaptureVideoDataOutput</code>对象获取视频帧</li>
<li>实现<code>AVCaptureVideoDataOutput</code>的代理</li>
<li>实现一个方法将接收到的<code>CMSampleBuffer</code>转换为<code>UIImage</code></li>
</ul>
<blockquote>
<p>提示: 为了展示核心代码, 这份示例省略了某些内容, 比如内存管理和通知的移除等. 使用AV Foundation之前, 你最好已经拥有Cocoa框架的使用经验.</p>
</blockquote>
<h2 id="创建和配置Capture-Session"><a href="#创建和配置Capture-Session" class="headerlink" title="创建和配置Capture Session"></a>创建和配置Capture Session</h2><p><code>AVCaptureSession</code>用来协调input和output之间的数据流. </p>
<pre><code>AVCaptureSession *session = [[AVCaptureSession alloc] init];
session.sessionPreset = AVCaptureSessionPresetMedium;
</code></pre>
<h2 id="创建和配置Device和Device-Input"><a href="#创建和配置Device和Device-Input" class="headerlink" title="创建和配置Device和Device Input"></a>创建和配置Device和Device Input</h2><p><code>AVCaptureDevice</code>表示捕捉设备, <code>AVCaptureInput</code>用来配置捕捉设备的端口</p>
<pre><code>AVCaptureDevice *device =
        [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];
 
NSError *error = nil;
AVCaptureDeviceInput *input =
        [AVCaptureDeviceInput deviceInputWithDevice:device error:&amp;error];
if (!input) &#123;
    // Handle the error appropriately.
&#125;
[session addInput:input];
</code></pre>
<h2 id="创建和配置Video-Data-Output"><a href="#创建和配置Video-Data-Output" class="headerlink" title="创建和配置Video Data Output"></a>创建和配置Video Data Output</h2><p>使用<code>AVCaptureVideoDataOutput</code>处理未压缩的视频帧. </p>
<pre><code>AVCaptureVideoDataOutput *output = [[AVCaptureVideoDataOutput alloc] init];
[session addOutput:output];
output.videoSettings =
                @&#123; (NSString *)kCVPixelBufferPixelFormatTypeKey : @(kCVPixelFormatType_32BGRA) &#125;;
output.minFrameDuration = CMTimeMake(1, 15);

dispatch_queue_t queue = dispatch_queue_create(&quot;MyQueue&quot;, NULL);
[output setSampleBufferDelegate:self queue:queue];
dispatch_release(queue);
</code></pre>
<h2 id="实现Sample-Buffer-代理方法"><a href="#实现Sample-Buffer-代理方法" class="headerlink" title="实现Sample Buffer 代理方法"></a>实现Sample Buffer 代理方法</h2><pre><code>- (void)captureOutput:(AVCaptureOutput *)captureOutput
         didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer
         fromConnection:(AVCaptureConnection *)connection &#123;
 
    UIImage *image = imageFromSampleBuffer(sampleBuffer);
    // Add your code here that uses the image.
&#125;	
</code></pre>
<p>将转换为UIImage的操作代码参见<a target="_blank" rel="noopener" href="https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/06_MediaRepresentations.html#//apple_ref/doc/uid/TP40010188-CH2-SW4"> Converting CMSampleBuffer to a UIImage Object</a>.</p>
<h2 id="开始和停止录制"><a href="#开始和停止录制" class="headerlink" title="开始和停止录制"></a>开始和停止录制</h2><p>配置capture session之后, 需要确保应用有访问相机的权限.</p>
<pre><code>NSString *mediaType = AVMediaTypeVideo;
 
[AVCaptureDevice requestAccessForMediaType:mediaType completionHandler:^(BOOL granted) &#123;
    if (granted)
    &#123;
        //Granted access to mediaType
        [self setDeviceAuthorized:YES];
    &#125;
    else
    &#123;
        //Not granted access to mediaType
        dispatch_async(dispatch_get_main_queue(), ^&#123;
        [[[UIAlertView alloc] initWithTitle:@&quot;AVCam!&quot;
                                    message:@&quot;AVCam doesn&#39;t have permission to use Camera, please change privacy settings&quot;
                                   delegate:self
                          cancelButtonTitle:@&quot;OK&quot;
                          otherButtonTitles:nil] show];
                [self setDeviceAuthorized:NO];
        &#125;);
    &#125;
&#125;];
</code></pre>
<p>当获取到相应的访问权限之后, 可以使用<code>startRunning</code>方法开始录制. <code>startRunning</code>会阻塞线程, 所以需要异步调用, 以免阻塞主线程.</p>
<pre><code>[session startRunning];
</code></pre>
<p>类似的调用<code>stopRunning</code>可以停止录制.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AVFoundation%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/" rel="tag"># AVFoundation编程指南</a>
              <a href="/tags/%E7%BF%BB%E8%AF%91/" rel="tag"># 翻译</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2016/09/09/%E7%BC%96%E8%BE%91Assets/" rel="prev" title="编辑Assets">
      <i class="fa fa-chevron-left"></i> 编辑Assets
    </a></div>
      <div class="post-nav-item">
    <a href="/2016/09/20/Asset%E7%9A%84%E9%87%8D%E7%BC%96%E7%A0%81%E5%8F%8A%E5%AF%BC%E5%87%BA/" rel="next" title="Asset的重编码及导出">
      Asset的重编码及导出 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Capture-Session%E5%8D%8F%E8%B0%83%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="nav-number">1.</span> <span class="nav-text">使用Capture Session协调数据流</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%85%8D%E7%BD%AECapture-Session"><span class="nav-number">1.1.</span> <span class="nav-text">配置Capture Session</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%91%E6%B5%8BCapture-Session%E7%9A%84%E7%8A%B6%E6%80%81"><span class="nav-number">1.2.</span> <span class="nav-text">监测Capture Session的状态</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8AVCaptureDevice%E8%A1%A8%E7%A4%BA%E8%BE%93%E5%85%A5%E8%AE%BE%E5%A4%87"><span class="nav-number">2.</span> <span class="nav-text">使用AVCaptureDevice表示输入设备</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%BE%E5%A4%87%E7%89%B9%E6%80%A7"><span class="nav-number">2.1.</span> <span class="nav-text">设备特性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8D%95%E6%8D%89%E8%AE%BE%E7%BD%AE"><span class="nav-number">2.2.</span> <span class="nav-text">捕捉设置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E7%84%A6%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.2.1.</span> <span class="nav-text">对焦模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%9D%E5%85%89%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.2.2.</span> <span class="nav-text">曝光模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%97%AA%E5%85%89%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.2.3.</span> <span class="nav-text">闪光模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%89%8B%E7%94%B5%E7%AD%92%E6%A8%A1%E5%BC%8F"><span class="nav-number">2.2.4.</span> <span class="nav-text">手电筒模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E7%A8%B3%E5%AE%9A%E6%80%A7"><span class="nav-number">2.2.5.</span> <span class="nav-text">视频稳定性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%99%BD%E5%B9%B3%E8%A1%A1"><span class="nav-number">2.2.6.</span> <span class="nav-text">白平衡</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BE%E7%BD%AE%E8%AE%BE%E5%A4%87%E6%96%B9%E5%90%91"><span class="nav-number">2.2.7.</span> <span class="nav-text">设置设备方向</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%BE%E5%A4%87%E9%85%8D%E7%BD%AE"><span class="nav-number">2.3.</span> <span class="nav-text">设备配置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%87%E6%8D%A2%E8%AE%BE%E5%A4%87"><span class="nav-number">2.4.</span> <span class="nav-text">切换设备</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8AVCaptureInput%E6%B7%BB%E5%8A%A0%E8%BE%93%E5%85%A5%E8%AE%BE%E5%A4%87"><span class="nav-number">3.</span> <span class="nav-text">使用AVCaptureInput添加输入设备</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8AVCaptureOutput%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE"><span class="nav-number">4.</span> <span class="nav-text">使用AVCaptureOutput输出数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BE%93%E5%87%BA%E4%B8%BA%E8%A7%86%E9%A2%91%E6%96%87%E4%BB%B6"><span class="nav-number">4.1.</span> <span class="nav-text">输出为视频文件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%80%E5%A7%8B%E5%BD%95%E5%88%B6"><span class="nav-number">4.1.1.</span> <span class="nav-text">开始录制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A1%AE%E4%BF%9D%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5%E6%88%90%E5%8A%9F"><span class="nav-number">4.1.2.</span> <span class="nav-text">确保文件写入成功</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8%E6%96%87%E4%BB%B6%E4%B8%AD%E6%B7%BB%E5%8A%A0%E5%85%83%E6%95%B0%E6%8D%AE"><span class="nav-number">4.1.3.</span> <span class="nav-text">在文件中添加元数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%84%E7%90%86%E8%A7%86%E9%A2%91%E5%B8%A7"><span class="nav-number">4.2.</span> <span class="nav-text">处理视频帧</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E6%97%B6%E7%9A%84%E6%80%A7%E8%83%BD%E8%80%83%E8%99%91"><span class="nav-number">4.2.1.</span> <span class="nav-text">视频处理时的性能考虑</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8D%95%E6%8D%89%E9%9D%99%E6%80%81%E5%9B%BE%E5%83%8F"><span class="nav-number">4.3.</span> <span class="nav-text">捕捉静态图像</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%83%8F%E7%B4%A0%E5%92%8C%E7%BC%96%E7%A0%81%E6%A0%BC%E5%BC%8F"><span class="nav-number">4.3.1.</span> <span class="nav-text">像素和编码格式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8D%95%E6%8D%89%E5%9B%BE%E7%89%87"><span class="nav-number">4.3.2.</span> <span class="nav-text">捕捉图片</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BD%95%E5%88%B6%E9%A2%84%E8%A7%88"><span class="nav-number">5.</span> <span class="nav-text">录制预览</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E9%A2%84%E8%A7%88"><span class="nav-number">5.1.</span> <span class="nav-text">视频预览</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E9%87%8D%E5%8A%9B%E6%A8%A1%E5%BC%8F"><span class="nav-number">5.1.1.</span> <span class="nav-text">视频重力模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E8%A7%88%E6%97%B6%E4%BD%BF%E7%94%A8%E7%82%B9%E5%87%BB%E8%81%9A%E7%84%A6%E5%8A%9F%E8%83%BD"><span class="nav-number">5.1.2.</span> <span class="nav-text">预览时使用点击聚焦功能</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B1%95%E7%A4%BA%E5%A3%B0%E9%9F%B3%E7%AD%89%E7%BA%A7"><span class="nav-number">5.2.</span> <span class="nav-text">展示声音等级</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B-%E6%8D%95%E6%8D%89%E8%A7%86%E9%A2%91%E5%B8%A7%E4%B8%BAUIImage%E5%AF%B9%E8%B1%A1"><span class="nav-number">6.</span> <span class="nav-text">示例: 捕捉视频帧为UIImage对象</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E5%92%8C%E9%85%8D%E7%BD%AECapture-Session"><span class="nav-number">6.1.</span> <span class="nav-text">创建和配置Capture Session</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E5%92%8C%E9%85%8D%E7%BD%AEDevice%E5%92%8CDevice-Input"><span class="nav-number">6.2.</span> <span class="nav-text">创建和配置Device和Device Input</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E5%92%8C%E9%85%8D%E7%BD%AEVideo-Data-Output"><span class="nav-number">6.3.</span> <span class="nav-text">创建和配置Video Data Output</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0Sample-Buffer-%E4%BB%A3%E7%90%86%E6%96%B9%E6%B3%95"><span class="nav-number">6.4.</span> <span class="nav-text">实现Sample Buffer 代理方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%80%E5%A7%8B%E5%92%8C%E5%81%9C%E6%AD%A2%E5%BD%95%E5%88%B6"><span class="nav-number">6.5.</span> <span class="nav-text">开始和停止录制</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">mangox</p>
  <div class="site-description" itemprop="description">每天进步一点点</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">130</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/changjianfeishui" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;changjianfeishui" rel="noopener" target="_blank"><i class="fa fa-tags fa-fw"></i></a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">mangox</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'Hl5bOvNBmh6xqvMEjzRRWMIP-gzGzoHsz',
      appKey     : '3n3m7ANssYrw0VgxYu87kQEL',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
